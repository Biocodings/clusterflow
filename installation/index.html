---
title: Installation Instructions
layout: toc
---

# Installation
To get started with Cluster Flow, first download the source files using the links on the left.

# Config file wizard
Cluster Flow comes with a command line wizard which can walk you through the creation of your personalised config file.

Simply run `cf --make_config` and answer the on screen questions and cluster flow will generate `~/clusterflow.config` for you. Sensible defaults are suggested.

# Cluster Flow config files
Cluster flow will search three locations for a config file every time it is run. Variables found in each file can override those read from a previous config file. They are, in order of priority:

* `<working directory>/clusterflow.config`
	* A config file found in the current working directory when a pipeline is executed has top priority, trumped only by command line parameters
* ``~/clusterflow.config``
	* A config file in your home directory can be used to set parameters such as notification level and e-mail address
* `<installation directory>/clusterflow.config`
	* A config file in the Cluster Flow installation directory is ideal for common settings specific to the environment

Config files contain key: value pairs. Syntax is as follows: `@key value` (tab delimited, one per line). Cluster Flow ships with an example config file called [clusterflow.config.example](https://github.com/ewels/clusterflow/blob/master/clusterflow.config.example "Browse the example config file on GitHub")

# Genome paths
Many modules within Cluster Flow require reference genomes for alignment. Cluster Flow comes with an interactive wizard to help you add new genome paths, just run: `cf --add_genome`

Genome paths are stored within files called `genomes.config` which are stored in the same directories as `clusterflow.config`. Within this file, each path is described with `@genome_path` followed by a key used when submitting the Cluster Flow run (eg. `--genome GRCh37`) followed by an absolute path. Optionally, species and assembly can be added after this.

There are four types of paths that can be specified:

* `@genome_path`
	* The directory containing a reference genome
* `@bowtie_path`
	* The file name base of a set of bowtie indices
* `@bowtie2_path`
	* The file name base of a set of bowtie 2 indices
* `@gtf_path`
	* The file name of a GTF file for a given genome.

All four types of path should share genome keys if applicable. The fields should be separated by a tab character. Cluster Flow ships with an example genomes file called [genomes.config.example](https://github.com/ewels/clusterflow/blob/master/genomes.config.example "Browse the example genomes file on GitHub")


# Config File settings
The following section describes the available variables that can be set in the config file. For an example, see the [clusterflow.config.example](https://github.com/ewels/clusterflow/blob/master/clusterflow.config.example "Browse the example config file on GitHub") file that comes bundled with Cluster Flow.

### @email
Sets your e-mail address, used for e-mail notifications.

### @check_updates
Cluster Flow can automatically check for new versions. If an update is available, it will print a notification each time you run a job. You can specify how often Cluster Flow should check for updates with this parameter. The syntax is a number followed by `d`, `w`, `m` or `y` for days, weeks, months or years. Cluster Flow will check for an update at runtime if this period or more has elapsed since you last ran it. You can disable update checks and alerts by setting `@check_updates 0` in your `~/clusterflow.config` file.

You can get Cluster Flow to manually check for updates by running cf `--check_updates`

### @split_files
The default number of input files to send to each run. Typically set to 1.

### @priority
The priority to give to cluster jobs.

### @max_runs
The maximum number of parallel runs that cluster flow will set off in one go. Default is 12 to avoid swamping the cluster for all other users.

### @notification
Multiple `@notification` key pairs can be set with the following values:

* complete
	* An e-mail notification is sent when all processing for all files has finished
* run
	* An e-mail is sent when each run finishes (each set of input files)
* end
	* A qsub notification e-mail is sent when each cluster job ends. Likely to result in a full inbox!
* suspend
	* A qsub notification e-mail is sent if a job is suspended
* abort
	* A qsub notification e-mail is sent if a job is aborted

Cluster Flow sends the `run` and `complete` notifications using the `cf_run_finished` and `cf_runs_all_finished` modules. These modules handle several tasks, such as cleaning useless warning messages from log files. E-mails contain the contents of all log files, plus a section at the top of highlighted messages, specified within log messages by being prefixed with `###CF`.

### @total_cores
The total number of cores available to a Cluster Flow pipeline. Modules are given a recommended number of cores so that resources can be allocated without swamping the cluster.

### @total_mem
The total amount of memory available to a Cluster Flow pipeline. Modules are given a recommended quota so that resources can be allocated without swamping the cluster.

### @ignore_modules
If you do not use environment modules on your system, you can prevent Cluster Flow from trying to use them (and giving a warning) by adding this line to your config file.

### @cluster_environment
Cluster Flow can submit jobs to both GRIDEngine and LSF cluster management systems. This configuration variable sets which environment to use. The possible options are:

* GRIDEngine
* SLURM
* LSF

It is worth noting that Cluster Flow has been developed on GRIDEngine and SLURM Clusters so is likely to be most robust on similar setups. The `--qstat` and `--qstatall` parameters do not currently work with LSR. If you'd like to have a go at implementing it, that would be great!
